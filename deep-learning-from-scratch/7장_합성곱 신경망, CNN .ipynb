{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c1c6697",
   "metadata": {},
   "source": [
    "## FC 계층의 문제점 \n",
    "\n",
    "FC에서는 인접하는 계층의 뉴런이 모두 연결되고 출력의 수는 임의로 정할 수 있다. FC의 문제점은 데이터의 형상이 무시된다는 점이다. 입력 데이터가 이미지인 경우를 예로 들면, 이미지는 통상 세로,가로, 색상으로 구성된 3차원 데이터 이다. 그러나 FC에 입력할 때는 3차원 데이터를 평평한 1차원 데이터로 평탄화 해줘야 한다. 이미지는 3차원 형상이며, 이 형상에는 공간적 정보가 담겨 있다. 그러나 FC는 형상을 무시하고 모든 입력 데이터를 동등한 뉴런으로 취급하여 형상에 담긴 정보를 살릴 수 없다.   \n",
    "\n",
    "-----\n",
    "\n",
    "But 합성곱 계층은 형상을 유지한다. 이미지도 3차원 데이터로 입력받으며, 마찬가지로 다음 계층에도 3차원 데이터로 전달된다. 그래서 CNN에서는 이미지처럼 형상을 가진 데이터를 제대로 이해하는 것이다.  \n",
    "\n",
    "CNN에서는 합성곱 계층의 입출력 데이터를 feature map이라고 한다. 합성곱 계층의 입력 데이터를 input feature map, 출력 데이터를 output feature map이라고 하는 식이다.   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0a8e04",
   "metadata": {},
   "source": [
    "## 합성곱 연산 \n",
    "합성곱 연산은 이미지 처리에서 말하는 필터 연산에 해당한다. \n",
    "\n",
    "<img src=\"https://compmath.korea.ac.kr/appmath2021/_images/cnn_op_order.png\" width=\"300\" height=\"300\"/>  \n",
    "\n",
    "합성곱 연산은 입력 데이터에 필터를 적용한다. 입력데이터는 세로 가로 방향의 형상을 가졌고, 필터 역시 세로 가로 방향의 차원을 갖는다. 데이터와 필터의 형상을 (h,w)로 표기하며, 예제에서는 입력은 (4,4), 필터는 (3,3), 출력은 (2,2)가 된다. 필터는 커널이라고 불린다.  \n",
    "\n",
    "합성곱 연산은 필터의 윈도우를 일정 간격으로 이동해가며 입력 데이터에 적용한다. 입력과 필터에서 대응하는 원소끼리 곱한 후 그 총합을 구한다(fused multiply-add,FMA). 결과를 출력의 해당 장소에 저장한다. 이 과정을 모든 장소에서 수행하며 합성곱 연산의 출력이 완성된다. \n",
    "\n",
    "---- \n",
    "\n",
    "CNN에서는 필터의 매개변수가 가중치에 해당한다. CNN에서도 편향이 존재 \n",
    "<img src=\"https://blog.kakaocdn.net/dn/bKQ8U7/btqJ1LThpX0/AYLeW7AKLkV8aVS5DOx9Pk/img.png\" width=\"400\" height=\"300\"/>  \n",
    "\n",
    "편향은 항상(1X1)만 존재한다. 그 하나의 값을 필터를 적용한 모든 원소에 더하는 것이다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98fb468",
   "metadata": {},
   "source": [
    "## 패팅 \n",
    "\n",
    "합성곱 연산을 수행하기 전에 입력 데이터 주변을 특정값으로 채우기도 한다. 이를 Padding이라고 하며 합성곱 연산에서 자주 이용하는 기법이다. \n",
    "\n",
    "<img src=\"https://blog.kakaocdn.net/dn/buF4ft/btqJZnrRhL0/XsApi9EoBjtjwSOkx9KLEk/img.png\" width=\"400\" height=\"300\"/>\n",
    "\n",
    "(4,4)인 입력 데이터에 패딩이 추가되어 (6,6)이 된다. 이 입력에 (3,3)크기의 필터를 걸면 (4,4) 크기의 출력 데이터가 생성된다. \n",
    "\n",
    "\n",
    "패팅은 주로 출력 크기를 조정할 목적으로 사용한다. (4,4)입력 데이터에 (3,3)필터를 적용하면 출력은 (2,2)가 되어, 입력보다 2만큼 줄어든다. 이는 합성곱 연산을 몇번이나 되풀이하는 심층 신경망에서는 문제가 될 수 있다. 합성곱 연산을 거칠 때마다 크기가 작아지면 어느 시점에서는 출력 크기가 1이 되어버리게 된다. 더 이상 합성곱 연산을 적용할 수 없다는 뜻이다. 이러한 사태를 막기 위해 패딩을 사용한다. **즉 입력 데이터의 공간적 크기를 고정한 채로 다음 계층에 전달할 수 있다.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43f9d9c",
   "metadata": {},
   "source": [
    "## 스트라이드 \n",
    "\n",
    "필터를 적용하는 위치의 간격을 스트라이드라고 한다. \n",
    "\n",
    "<img src=\"https://t1.daumcdn.net/cfile/tistory/99272D3D5C4D268B1C\" width=\"400\" height=\"300\"/>\n",
    "\n",
    "\n",
    "패딩, 스트라이드, 출력크기 계산 \n",
    "* 입력 크기 (H,W) , 필터 크기 (FH, FW), 출력크기(OH, OW), 패딩(P) ,스트라이드(S)  \n",
    "$ OH = H + 2P -FH /  S + 1$  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff73557",
   "metadata": {},
   "source": [
    "## 3차원 데이터의 합성곱 연산 \n",
    "\n",
    "<img src=\"https://blog.kakaocdn.net/dn/c6yIAl/btqKdEEQQTb/5uwHwi5el7pjkuCKhfkmO1/img.png\" width=\"300\" height=\"300\"/>\n",
    "\n",
    "\n",
    "2차원일 때와 비교하면 길이 방향으로 특징 맵이 늘어났다. 채널 쪽으로 특징 맵이 여러 개 있다면 입력데이터와 필터의 합성곱 연산을 채널마다 수행하고, 그 결과를 더해서 하나의 출력을 얻는다.  \n",
    "\n",
    "3차원의 합성곱 연산에서 주의할 점은 입력 데이터의 채널 수와 필터의 채널 수가 같아야 한다는 것이다. 반면 필터 자체의 크기는 원하는 값으로 설정할 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba90f87f",
   "metadata": {},
   "source": [
    "## 블록으로 생각\n",
    "\n",
    "3차원의 합성곱 연산은 데이터와 필터를 직육면체 블록이라고 생각하면 쉽다. \n",
    "\n",
    "<img src=\"http://3.bp.blogspot.com/-Sd2tEjB9ZLQ/WYJtnAea0LI/AAAAAAAALN4/7BFnDCofuusdoPYPB88xUWWIlC5qZzcawCK4BGAYYCw/s1600/o12.PNG\" width=\"300\" height=\"300\"/>\n",
    "\n",
    "그림과 같이 필터를 FN개 적용하면 출력 맵도 FN개가 생성된다. 그리고 그 FN개의 맵을 모으면 형상이 (FN, OH, OW)인 블록이 완성된다. 이 완성된 블록을 다음 계층으로 넘기겠다는 것이 CNN처리 흐름이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056c8722",
   "metadata": {},
   "source": [
    "## 배치 처리 \n",
    "\n",
    "신경망 처리에서는 입력 데이터를 한 덩어리로 묶어 배치로 처리 했다. 완전연결 신경망을 구현하면서는 이 방식을 지원하여 처리 효율을 높이고, 미니배치 방식의 학습도 지원하도록 했다.  \n",
    "\n",
    "합성곱 연산도 마찬가지로 배치 처리를 지원하고자 한다. 그래서 각 계층을 흐르는 데이터의 차원을 하나 늘려 4차원 데이터로 저장한다. 구체적으로는 데이터를 (데이터 수, 채널 수, 높이, 너비) 순으로 저장한다. \n",
    "\n",
    "\n",
    "<img src=\"https://img1.daumcdn.net/thumb/R800x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fc9AhzF%2FbtqJ91URvwj%2FN6C3OueXq8ee8x1c96OwU1%2Fimg.png\" width=\"500\" height=\"300\"/>\n",
    "\n",
    "배치 처리 시의 데이터 흐름을 나타낸 위의 그림을 보면 각 데이터의 선두에 배치용 차원을 추가 했다. 이처럼 데이터 4차원 형상을 가진 채 각 계층을 타고 흐른다. 주의할 점은 신경망에 4차원 데이터가 하나 흐를 때마다 데이터 N개에 대한 합성곱 연산이 이뤄진다는 것이다. 즉 N회 분의 처리를 한번에 수행하는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc1a051",
   "metadata": {},
   "source": [
    "## 풀링계층 \n",
    "\n",
    "풀링은 세로, 가로 방향의 공간을 줄이는 연산이다. 아래 사진과 같이 2x2영역을 원소 하나로 집약하여 공간 크기를 줄인다. \n",
    "\n",
    "<img src=\"https://images.velog.io/images/seoyeon/post/a2d01d95-f04b-4296-b7da-e4f31b7dca22/fig-7-14.png\" width=\"500\" height=\"300\"/>\n",
    "\n",
    "2x2 최대 출링을 스트라이드 2로 처리하는 순서이다. 최대 풀링은 최댓값을 구하는 연산으로 2ㅌ2는 대상 영역의 크기를 말한다. 즉 2x2 최대 풀링은 그림과 같이 2x2 크기의 영역에서 가장 큰 원소 하나를 꺼낸다. 또 스트라이드는 이 예에서는 2로 설정했으므로 2x2 윈도우가 원소 2칸 간격으로 이동한다. 풀링의 윈도우 크기와 스트라이드는 같은 값으로 설정하는 것이 보통이다. 예를 들어 윈도우가 3x3이면 스트라이드는 3으로 , 윈도우가 4x4면 스트라이들 4로 설정한다. \n",
    "\n",
    " \n",
    "풀링은 최대 풀링 외에도 평균풀링 등이 있다. 최대 풀링은 대상 영역에서 최댓값을 취하는 연산인 반면, 평균 풀링은 대상 영역의 평균을 계산한다. 이미지 인식 분야에서는 주로 최대 풀링을 사용한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1758bec",
   "metadata": {},
   "source": [
    "## 풀링 계층의 특징 \n",
    "\n",
    "#### 학습해야 할 매개변수가 없다. \n",
    "풀링 계층은 합성곱 계층과 달리 학습해야 할 매개변수가 없다. 풀링은 대상 영역에서 최댓값이나 평균을 취하는 명확한 처리이므로 특별히 학습할 것이 없다. \n",
    "\n",
    "------\n",
    "\n",
    "#### 채널 수가 변하지 않는다.\n",
    "풀링 연산은 입력 데이터의 채널 수 그대로 출력 데이터로 내보낸다. 채널마다 독립적으로 계산하기 때문이다. \n",
    "\n",
    "<img src=\"https://blog.kakaocdn.net/dn/cNb84t/btqQpuCYiUV/NWYKDO2CcMtz3nlYLDOXo0/img.png\" width=\"300\" height=\"300\"/>\n",
    "\n",
    "----\n",
    "\n",
    "#### 입력의 변화에 영향을 적게 받는다.  \n",
    "입력 데이터가 조금 변해도 풀링의 결과는 잘 변하지 않는다. \n",
    "\n",
    "<img src=\"https://blog.kakaocdn.net/dn/vi1Rm/btqQnZXvAtS/OcgYZouhqrok3cSQ1kvqp0/img.png\" width=\"500\" height=\"300\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330c8e4c",
   "metadata": {},
   "source": [
    "## 합성곱 / 풀링 계층 구현 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03d9871d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1, 28, 28)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 높이 28, 너비 28, 채널 1 , 데이터 10 \n",
    "x = np.random.rand(10, 1, 28, 28) \n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f994f415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d17f5e33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1124b057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.94399528, 0.05574361, 0.91575974, 0.14034974, 0.89501151,\n",
       "        0.43477469, 0.84152501, 0.10420262, 0.82770749, 0.72752592,\n",
       "        0.602006  , 0.62398557, 0.14816292, 0.83765399, 0.00988885,\n",
       "        0.72343115, 0.08721434, 0.09237438, 0.40076725, 0.6619664 ,\n",
       "        0.84557085, 0.73696232, 0.39815696, 0.25388735, 0.02995573,\n",
       "        0.90406857, 0.96854092, 0.53922813],\n",
       "       [0.19044526, 0.01997179, 0.04248451, 0.69688859, 0.91059739,\n",
       "        0.63906972, 0.89063641, 0.24302537, 0.93163404, 0.78083393,\n",
       "        0.22032407, 0.19819646, 0.813335  , 0.70538713, 0.41552885,\n",
       "        0.66289685, 0.2265803 , 0.30112422, 0.2935574 , 0.01268543,\n",
       "        0.41990443, 0.31558687, 0.71746888, 0.54560642, 0.33672804,\n",
       "        0.03418158, 0.67527255, 0.24462158],\n",
       "       [0.03584046, 0.44558427, 0.94840789, 0.02449071, 0.36043593,\n",
       "        0.43589888, 0.83248143, 0.34661481, 0.20913731, 0.83604049,\n",
       "        0.00261597, 0.26757857, 0.24199201, 0.45464285, 0.30038774,\n",
       "        0.69303902, 0.78488541, 0.11696857, 0.63942032, 0.32589642,\n",
       "        0.74709878, 0.33679012, 0.48655946, 0.89038393, 0.2629062 ,\n",
       "        0.65099762, 0.34172244, 0.22752666],\n",
       "       [0.47702808, 0.60415057, 0.74349618, 0.8928524 , 0.20204068,\n",
       "        0.47809183, 0.20020411, 0.5460148 , 0.35692162, 0.60896242,\n",
       "        0.97153658, 0.13359642, 0.5572379 , 0.86761392, 0.59018271,\n",
       "        0.41711695, 0.59651508, 0.7418049 , 0.82384798, 0.26191745,\n",
       "        0.86421306, 0.23639848, 0.43362039, 0.48339407, 0.75907714,\n",
       "        0.56862069, 0.19431996, 0.50815274],\n",
       "       [0.16347045, 0.75882383, 0.90093563, 0.13395645, 0.226647  ,\n",
       "        0.03317615, 0.91359259, 0.22086461, 0.751871  , 0.58192054,\n",
       "        0.81293145, 0.70026646, 0.75181915, 0.7856888 , 0.88019279,\n",
       "        0.34540233, 0.13760021, 0.64611829, 0.58901349, 0.94015441,\n",
       "        0.85507565, 0.55947649, 0.89672011, 0.59320194, 0.03768108,\n",
       "        0.29740959, 0.46273153, 0.82551637],\n",
       "       [0.06062723, 0.91061955, 0.10656904, 0.80216926, 0.04528554,\n",
       "        0.29960922, 0.57023686, 0.78110019, 0.43487817, 0.2937848 ,\n",
       "        0.72833212, 0.08313862, 0.80025213, 0.16247969, 0.46712326,\n",
       "        0.74599865, 0.42259963, 0.98070379, 0.99586576, 0.56051604,\n",
       "        0.91329048, 0.77241719, 0.93835085, 0.44213547, 0.84380929,\n",
       "        0.8962682 , 0.95065819, 0.21475072],\n",
       "       [0.89442184, 0.70642143, 0.99580765, 0.58669649, 0.98994923,\n",
       "        0.46656004, 0.39309409, 0.57251112, 0.74781291, 0.85083049,\n",
       "        0.80086254, 0.54099658, 0.68441177, 0.56600857, 0.33292134,\n",
       "        0.94727798, 0.10283501, 0.87367258, 0.66882209, 0.51031468,\n",
       "        0.19251735, 0.46048266, 0.31966034, 0.16154342, 0.7258853 ,\n",
       "        0.1692891 , 0.84345409, 0.94258279],\n",
       "       [0.09896255, 0.47547115, 0.46522377, 0.856246  , 0.93815635,\n",
       "        0.64055244, 0.09642676, 0.02908166, 0.22944549, 0.08583184,\n",
       "        0.44896799, 0.35549536, 0.95758199, 0.62277015, 0.38200029,\n",
       "        0.89379243, 0.92464704, 0.48753834, 0.6454216 , 0.52558998,\n",
       "        0.9245251 , 0.09306557, 0.61586382, 0.29447113, 0.49673368,\n",
       "        0.60432137, 0.66561177, 0.42924058],\n",
       "       [0.5054151 , 0.482707  , 0.81669848, 0.31775379, 0.56539258,\n",
       "        0.13189286, 0.75121362, 0.21408539, 0.68770304, 0.40716542,\n",
       "        0.71092556, 0.39331329, 0.73217684, 0.9525184 , 0.78179587,\n",
       "        0.81625154, 0.06257178, 0.18555579, 0.39965064, 0.96604201,\n",
       "        0.37653202, 0.10444827, 0.17341217, 0.59513479, 0.95871787,\n",
       "        0.2365004 , 0.90999125, 0.52457915],\n",
       "       [0.54438671, 0.22819148, 0.6193549 , 0.17656342, 0.89372474,\n",
       "        0.52716791, 0.75873501, 0.9933735 , 0.80761216, 0.12383182,\n",
       "        0.39015382, 0.59227904, 0.01090068, 0.69608454, 0.52196895,\n",
       "        0.81933238, 0.75796121, 0.56780035, 0.93855481, 0.0890434 ,\n",
       "        0.21631034, 0.42422957, 0.18733461, 0.23079469, 0.23316897,\n",
       "        0.8152382 , 0.20332572, 0.24044424],\n",
       "       [0.7146403 , 0.81143919, 0.32408444, 0.22298962, 0.03489971,\n",
       "        0.28892798, 0.82062844, 0.68565825, 0.32033303, 0.87378855,\n",
       "        0.82853387, 0.07077764, 0.26021524, 0.10237817, 0.23805516,\n",
       "        0.44588122, 0.01593198, 0.93428128, 0.55670203, 0.2139183 ,\n",
       "        0.40924801, 0.77177969, 0.68803241, 0.50987219, 0.72798041,\n",
       "        0.79509781, 0.91622731, 0.26379792],\n",
       "       [0.56088227, 0.35261429, 0.99886767, 0.49726437, 0.70062573,\n",
       "        0.5530361 , 0.73579119, 0.59882476, 0.12015234, 0.94204828,\n",
       "        0.74369349, 0.21446506, 0.2694088 , 0.7634097 , 0.42754932,\n",
       "        0.64749893, 0.60076081, 0.10330906, 0.44852972, 0.33637667,\n",
       "        0.89944286, 0.31779829, 0.30537195, 0.22115751, 0.36239921,\n",
       "        0.68451823, 0.87253848, 0.85069753],\n",
       "       [0.93735982, 0.62001744, 0.40641666, 0.82588838, 0.79475903,\n",
       "        0.82730759, 0.61147533, 0.25010302, 0.61478057, 0.59497316,\n",
       "        0.99250319, 0.04172041, 0.11750779, 0.49837771, 0.47639855,\n",
       "        0.31441819, 0.51487505, 0.77458933, 0.00723778, 0.48849519,\n",
       "        0.98109923, 0.68658547, 0.53607625, 0.33275035, 0.56387301,\n",
       "        0.58609567, 0.01917518, 0.46848565],\n",
       "       [0.54406045, 0.62241178, 0.22836407, 0.77344159, 0.65096029,\n",
       "        0.48965644, 0.05045439, 0.75617356, 0.51617049, 0.48740119,\n",
       "        0.912505  , 0.98480161, 0.70943119, 0.86735338, 0.59801963,\n",
       "        0.13823348, 0.11505008, 0.53989026, 0.78614639, 0.24977143,\n",
       "        0.57398398, 0.76860345, 0.46507221, 0.67251686, 0.70223972,\n",
       "        0.604581  , 0.07103054, 0.83696335],\n",
       "       [0.12705519, 0.77254484, 0.02286866, 0.10731925, 0.11443919,\n",
       "        0.52114565, 0.44448005, 0.51052115, 0.59192776, 0.62083939,\n",
       "        0.42744373, 0.15901541, 0.79382174, 0.20117746, 0.75945908,\n",
       "        0.53920775, 0.66834684, 0.93534022, 0.47655558, 0.51384683,\n",
       "        0.77953412, 0.80391349, 0.74401246, 0.8899636 , 0.54089085,\n",
       "        0.48868509, 0.18264697, 0.35161852],\n",
       "       [0.21006908, 0.99255177, 0.54788239, 0.95803348, 0.51938651,\n",
       "        0.18217394, 0.9442807 , 0.72367401, 0.7915794 , 0.18633546,\n",
       "        0.13138008, 0.49213075, 0.13102408, 0.14798411, 0.46170477,\n",
       "        0.52616631, 0.41110436, 0.21383603, 0.3610008 , 0.72533935,\n",
       "        0.46514091, 0.88315194, 0.9075643 , 0.601175  , 0.4831257 ,\n",
       "        0.27545452, 0.59169588, 0.82525942],\n",
       "       [0.69751991, 0.47943285, 0.2880259 , 0.48345949, 0.28637661,\n",
       "        0.76194751, 0.28680976, 0.50085836, 0.76143216, 0.35557555,\n",
       "        0.57149745, 0.65856362, 0.54970032, 0.28073081, 0.45680583,\n",
       "        0.44938615, 0.47636949, 0.60464469, 0.12364969, 0.87228541,\n",
       "        0.10980588, 0.14209392, 0.83248686, 0.02730844, 0.3540751 ,\n",
       "        0.76169004, 0.61215456, 0.83510359],\n",
       "       [0.87737276, 0.61838557, 0.32974883, 0.02301479, 0.01889086,\n",
       "        0.74434161, 0.63063069, 0.39035991, 0.17890429, 0.15146602,\n",
       "        0.82620464, 0.57804482, 0.98505749, 0.39795428, 0.91662802,\n",
       "        0.13812951, 0.15739303, 0.48226101, 0.29554333, 0.8797022 ,\n",
       "        0.14916949, 0.83459429, 0.96359619, 0.80050099, 0.77819342,\n",
       "        0.83518319, 0.91600006, 0.62397501],\n",
       "       [0.00887667, 0.76134553, 0.005313  , 0.49671102, 0.98858632,\n",
       "        0.93585577, 0.9871317 , 0.05074899, 0.22921078, 0.36494288,\n",
       "        0.27764298, 0.46489471, 0.90125288, 0.8696079 , 0.7903971 ,\n",
       "        0.60500532, 0.722585  , 0.88350676, 0.89975113, 0.37385758,\n",
       "        0.88320386, 0.28267318, 0.89334801, 0.10352748, 0.96619642,\n",
       "        0.10163505, 0.68897983, 0.7413482 ],\n",
       "       [0.28369061, 0.36001916, 0.28825636, 0.70646343, 0.43736833,\n",
       "        0.23113378, 0.39915437, 0.42707409, 0.36100595, 0.71127783,\n",
       "        0.3823675 , 0.26498831, 0.09348152, 0.25544032, 0.01157682,\n",
       "        0.08667513, 0.6665692 , 0.4840274 , 0.55164604, 0.64873001,\n",
       "        0.37234865, 0.98380318, 0.68929055, 0.70616821, 0.40869696,\n",
       "        0.7468561 , 0.18083353, 0.10828802],\n",
       "       [0.69548401, 0.10771632, 0.09518385, 0.03815759, 0.5506607 ,\n",
       "        0.71737069, 0.94401619, 0.36574191, 0.24711707, 0.6967156 ,\n",
       "        0.43131698, 0.26487779, 0.83970822, 0.55776452, 0.71654631,\n",
       "        0.8790127 , 0.83637636, 0.77186781, 0.56980271, 0.78474173,\n",
       "        0.3819235 , 0.57505064, 0.82002649, 0.41119746, 0.96412908,\n",
       "        0.8588463 , 0.84015716, 0.48373396],\n",
       "       [0.8246793 , 0.57787013, 0.27121809, 0.67943039, 0.30639652,\n",
       "        0.19616035, 0.41738695, 0.46164895, 0.51233907, 0.77897863,\n",
       "        0.84086966, 0.31597818, 0.45398491, 0.08755029, 0.89725918,\n",
       "        0.94005554, 0.96072553, 0.66161693, 0.37572381, 0.98109082,\n",
       "        0.32038335, 0.43407025, 0.78536376, 0.10029303, 0.42956258,\n",
       "        0.67646896, 0.26708808, 0.87560001],\n",
       "       [0.75712007, 0.90925683, 0.49964114, 0.82046434, 0.1583611 ,\n",
       "        0.65022966, 0.02287436, 0.82728016, 0.50154617, 0.11281955,\n",
       "        0.28700648, 0.67937561, 0.0122638 , 0.5160798 , 0.07813837,\n",
       "        0.68406694, 0.04004781, 0.09453765, 0.64535061, 0.14681866,\n",
       "        0.95565225, 0.66433265, 0.40889332, 0.09452162, 0.98062009,\n",
       "        0.16958645, 0.98771364, 0.60884937],\n",
       "       [0.26311952, 0.2725618 , 0.17443107, 0.62059227, 0.90736079,\n",
       "        0.04769849, 0.1367972 , 0.37240793, 0.49075795, 0.25482995,\n",
       "        0.18399832, 0.57031734, 0.46035334, 0.91167541, 0.44560529,\n",
       "        0.48293114, 0.70912248, 0.06300743, 0.76519112, 0.76092444,\n",
       "        0.59942656, 0.46445655, 0.34252242, 0.65199392, 0.86100372,\n",
       "        0.49784308, 0.53325075, 0.98706431],\n",
       "       [0.89799506, 0.78207271, 0.6867694 , 0.97320259, 0.72603895,\n",
       "        0.91031046, 0.52017324, 0.58482629, 0.98510169, 0.46553791,\n",
       "        0.91178152, 0.16145945, 0.17363239, 0.55449452, 0.46304609,\n",
       "        0.84399014, 0.96980479, 0.8255082 , 0.50492561, 0.52577195,\n",
       "        0.58207183, 0.76354894, 0.93628353, 0.78461229, 0.68858022,\n",
       "        0.06194523, 0.69319083, 0.32532126],\n",
       "       [0.56156521, 0.46265585, 0.98705479, 0.64192152, 0.53457906,\n",
       "        0.13434879, 0.4050642 , 0.68586797, 0.88703564, 0.8006765 ,\n",
       "        0.31073886, 0.08023191, 0.48011694, 0.03858385, 0.68136259,\n",
       "        0.86248612, 0.50896616, 0.14651011, 0.36276606, 0.17095853,\n",
       "        0.61029678, 0.09721294, 0.22894341, 0.0380764 , 0.0891872 ,\n",
       "        0.49943148, 0.9616736 , 0.8373205 ],\n",
       "       [0.42156221, 0.42970634, 0.63318526, 0.17176948, 0.334102  ,\n",
       "        0.79719423, 0.6669973 , 0.02471931, 0.95998249, 0.22725189,\n",
       "        0.31872675, 0.18387065, 0.4927204 , 0.87428932, 0.2812575 ,\n",
       "        0.07811754, 0.91244438, 0.43906195, 0.24880899, 0.59765358,\n",
       "        0.33650517, 0.47145763, 0.55509314, 0.83020417, 0.7373911 ,\n",
       "        0.59439257, 0.02157955, 0.03110199],\n",
       "       [0.28290018, 0.99425396, 0.68186467, 0.38741148, 0.82216742,\n",
       "        0.49782363, 0.10128749, 0.38001338, 0.57968815, 0.48662155,\n",
       "        0.75938348, 0.73314101, 0.4407574 , 0.9149307 , 0.72241067,\n",
       "        0.08581911, 0.80360318, 0.794723  , 0.44805439, 0.72973402,\n",
       "        0.79384035, 0.71890179, 0.97933987, 0.7290082 , 0.22075866,\n",
       "        0.64260597, 0.90142853, 0.82773587]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b485350",
   "metadata": {},
   "source": [
    "## im2col로 데이터 전개 \n",
    "\n",
    "합성곱 연산을 곧이 곧개로 구현하려면 for문을 겹겹이 써야한다. for문 대신 im2col라는 편의 함수를 사용해 간단하게 구현해본다.  \n",
    "im2col는 입력 데이터를 필터링(가중치 계산)하기 좋게 전개하는 함수이다. 3차원 입력 데이터에 im2col을 적용하면 2차원 행렬로 바꿔준다. \n",
    "\n",
    "<img src=\"https://velog.velcdn.com/images%2Fseoyeon%2Fpost%2F688d109f-ffc3-40cc-aeec-eafe1b74caa5%2F%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA%202021-08-11%20%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE%202.29.23.png\" width=\"400\" height=\"300\"/>\n",
    "\n",
    "\n",
    "im2col는 필터링 하기 좋게 데이터를 전개한다. 구체적으로는 밑에 그림처럼 입력 데이터에서 필터를 적용하는 영역을 한 줄로 늘어 준다. 이 전개를 필터를 적용하는 모든 영역에서 수행하는게 im2col이다. \n",
    "\n",
    "<img src=\"https://blog.kakaocdn.net/dn/bH6SNd/btqKdGDF3De/KkRTiJdkLpXNtkksS4oRH1/img.png\" width=\"400\" height=\"300\"/>\n",
    "\n",
    "실제 상황에서는 영역이 겹치는 경우가 대부분이다. 필터 적용 영역이 겹치게 되면 im2col로 전개한 후의 원소 수가 원래 블록의 원소 수보다 많아진다. 그래서 im2col를 사용하여 구현하면 메모리를 더 많이 소비하는 단점이 있다. 하지만 컴퓨터는 큰 행렬을 묶어서 계산하는 데 탁월하다. 문제를 행렬 계산으로 만들면 선행 대수 라이브러리를 활용해 효율을 높일 수 있다. \n",
    "\n",
    "im2col로 입력 데이터를 전개한 다음에는 합성곱 계층의 필터를 1열로 전개하고 두 행렬의 곱을 계산하면 된다. 이는 FC 계층의 Affine 계층에서 한 것과 거의 같다. \n",
    "\n",
    "<img src=\"https://blog.kakaocdn.net/dn/bnw3ZZ/btqJ6cRdacS/0ugCudtKO9CevNOWKY30Ik/img.png\" width=\"500\" height=\"300\"/>\n",
    "\n",
    "\n",
    "위와 같이 im2col 방식으로 출력한 결과는 2차원 행렬이다. CNN은 데이터를 4차원 배열로 저장하므로 2차원인 출력 데이터를 4차원으로 변형한다. 이상이 합성곱 계층의 구현 흐름이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ba1dcd",
   "metadata": {},
   "source": [
    "## CNN  구현 \n",
    "\n",
    "CNN - RELU - Pooling - Affine - RELU - Affine - Softmax 순으로 진행된다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d772f980",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from common.layers import *\n",
    "from common.gradient import numerical_gradient\n",
    "\n",
    "\n",
    "class SimpleConvNet:\n",
    "    \"\"\"단순한 합성곱 신경망\n",
    "    \n",
    "    conv - relu - pool - affine - relu - affine - softmax\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_size : 입력 크기（MNIST의 경우엔 784）\n",
    "    hidden_size_list : 각 은닉층의 뉴런 수를 담은 리스트（e.g. [100, 100, 100]）\n",
    "    output_size : 출력 크기（MNIST의 경우엔 10）\n",
    "    activation : 활성화 함수 - 'relu' 혹은 'sigmoid'\n",
    "    weight_init_std : 가중치의 표준편차 지정（e.g. 0.01）\n",
    "        'relu'나 'he'로 지정하면 'He 초깃값'으로 설정\n",
    "        'sigmoid'나 'xavier'로 지정하면 'Xavier 초깃값'으로 설정\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=(1, 28, 28), \n",
    "                 conv_param={'filter_num':30, 'filter_size':5, 'pad':0, 'stride':1},\n",
    "                 hidden_size=100, output_size=10, weight_init_std=0.01):\n",
    "        filter_num = conv_param['filter_num']\n",
    "        filter_size = conv_param['filter_size']\n",
    "        filter_pad = conv_param['pad']\n",
    "        filter_stride = conv_param['stride']\n",
    "        input_size = input_dim[1]\n",
    "        conv_output_size = (input_size - filter_size + 2*filter_pad) / filter_stride + 1\n",
    "        pool_output_size = int(filter_num * (conv_output_size/2) * (conv_output_size/2))\n",
    "\n",
    "        # 가중치 초기화\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * \\\n",
    "                            np.random.randn(filter_num, input_dim[0], filter_size, filter_size)\n",
    "        self.params['b1'] = np.zeros(filter_num)\n",
    "        self.params['W2'] = weight_init_std * \\\n",
    "                            np.random.randn(pool_output_size, hidden_size)\n",
    "        self.params['b2'] = np.zeros(hidden_size)\n",
    "        self.params['W3'] = weight_init_std * \\\n",
    "                            np.random.randn(hidden_size, output_size)\n",
    "        self.params['b3'] = np.zeros(output_size)\n",
    "\n",
    "        # 계층 생성\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Conv1'] = Convolution(self.params['W1'], self.params['b1'],\n",
    "                                           conv_param['stride'], conv_param['pad'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Pool1'] = Pooling(pool_h=2, pool_w=2, stride=2)\n",
    "        self.layers['Affine1'] = Affine(self.params['W2'], self.params['b2'])\n",
    "        self.layers['Relu2'] = Relu()\n",
    "        self.layers['Affine2'] = Affine(self.params['W3'], self.params['b3'])\n",
    "\n",
    "        self.last_layer = SoftmaxWithLoss()\n",
    "\n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        \"\"\"손실 함수를 구한다.\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 입력 데이터\n",
    "        t : 정답 레이블\n",
    "        \"\"\"\n",
    "        y = self.predict(x)\n",
    "        return self.last_layer.forward(y, t)\n",
    "\n",
    "    def accuracy(self, x, t, batch_size=100):\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "        \n",
    "        acc = 0.0\n",
    "        \n",
    "        for i in range(int(x.shape[0] / batch_size)):\n",
    "            tx = x[i*batch_size:(i+1)*batch_size]\n",
    "            tt = t[i*batch_size:(i+1)*batch_size]\n",
    "            y = self.predict(tx)\n",
    "            y = np.argmax(y, axis=1)\n",
    "            acc += np.sum(y == tt) \n",
    "        \n",
    "        return acc / x.shape[0]\n",
    "\n",
    "    def numerical_gradient(self, x, t):\n",
    "        \"\"\"기울기를 구한다（수치미분）.\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 입력 데이터\n",
    "        t : 정답 레이블\n",
    "        Returns\n",
    "        -------\n",
    "        각 층의 기울기를 담은 사전(dictionary) 변수\n",
    "            grads['W1']、grads['W2']、... 각 층의 가중치\n",
    "            grads['b1']、grads['b2']、... 각 층의 편향\n",
    "        \"\"\"\n",
    "        loss_w = lambda w: self.loss(x, t)\n",
    "\n",
    "        grads = {}\n",
    "        for idx in (1, 2, 3):\n",
    "            grads['W' + str(idx)] = numerical_gradient(loss_w, self.params['W' + str(idx)])\n",
    "            grads['b' + str(idx)] = numerical_gradient(loss_w, self.params['b' + str(idx)])\n",
    "\n",
    "        return grads\n",
    "\n",
    "    def gradient(self, x, t):\n",
    "        \"\"\"기울기를 구한다(오차역전파법).\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 입력 데이터\n",
    "        t : 정답 레이블\n",
    "        Returns\n",
    "        -------\n",
    "        각 층의 기울기를 담은 사전(dictionary) 변수\n",
    "            grads['W1']、grads['W2']、... 각 층의 가중치\n",
    "            grads['b1']、grads['b2']、... 각 층의 편향\n",
    "        \"\"\"\n",
    "        # forward\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # backward\n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "\n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        # 결과 저장\n",
    "        grads = {}\n",
    "        grads['W1'], grads['b1'] = self.layers['Conv1'].dW, self.layers['Conv1'].db\n",
    "        grads['W2'], grads['b2'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n",
    "        grads['W3'], grads['b3'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n",
    "\n",
    "        return grads\n",
    "        \n",
    "    def save_params(self, file_name=\"params.pkl\"):\n",
    "        params = {}\n",
    "        for key, val in self.params.items():\n",
    "            params[key] = val\n",
    "        with open(file_name, 'wb') as f:\n",
    "            pickle.dump(params, f)\n",
    "\n",
    "    def load_params(self, file_name=\"params.pkl\"):\n",
    "        with open(file_name, 'rb') as f:\n",
    "            params = pickle.load(f)\n",
    "        for key, val in params.items():\n",
    "            self.params[key] = val\n",
    "\n",
    "        for i, key in enumerate(['Conv1', 'Affine1', 'Affine2']):\n",
    "            self.layers[key].W = self.params['W' + str(i+1)]\n",
    "            self.layers[key].b = self.params['b' + str(i+1)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
