{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e64a7ca",
   "metadata": {},
   "source": [
    "## EfficientNet \n",
    "\n",
    "모델을 크게 만드는 3가지 방법 \n",
    "1. network의 depth를 깊게 만드는 것 \n",
    "2. channel width(filter 개수)늘리는 것 (width가 넓을 수록 미세한 정보가 많이 담겨진다.)\n",
    "3. input image의 해상도를 올리는 것 \n",
    "\n",
    "\n",
    "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FkDFgx%2FbtqSpGpf1hY%2F2HHtBmi4OPhirT7jZ21oYk%2Fimg.png\" width=\"600\" height=\"300\"/>  \n",
    "\n",
    "-----\n",
    "\n",
    "* 한정된 자원으로 최대의 효율을 내기 위한 방법으로 model scaling을 시스템적으로 분석하여 더 나은 성능을 얻고자 했다.\n",
    "* 새로운 scaling 방법으로 compount coeffiecient를 제안 \n",
    "\n",
    "#### Related work \n",
    "\n",
    "* ConvNet Accuracy - AlexNet 이후 ImageNet competition에서 더 깊어지고 커지면서 정확도가 높아지는 모델들이 여럿 발표되었다. 최근 발표되는 모델들은 ImageNet뿐만 아니라 다른 데이터셋에서도 잘 작동한다. 그러나 정확도는 높아졌지만, 사용하는 자원 역시 크게 늘어났다.\n",
    "\n",
    "* ConvNet Efficiency - 깊은 ConvNets는 좀좀 over-parameterized된다. 효율을 높이기 위해 모델 압축하는 여러 기법이 제안되었다: SqueezeNets, MobileNets, ShuffleNets 등.\n",
    "\n",
    "* Model Scaling ResNet(ResNet-18, ResNet-50, ResNet-200)은 깊이를 달리 하였다. MobileNets는 network width를 달리 하였다. 또한 이미지 해상도가 높아지면 (찾아낼 정보가 많아서) 정확도를 높아진다. (물론 계산량도 많이 늘어난다.)\n",
    "\n",
    "------\n",
    "\n",
    "#### Scaling Dimentions \n",
    "* Depth: 네트워크의 깊이가 증가할수록 모델의 capacity가 커지고 더 복잡한 feature를 잡아낼 수 있지만, vanishing gradient의 문제로 학습시키기가 더 어려워진다. 이를 해결하기 위해 Batch Norm, Residual Connection 등의 여러 기법들이 등장하였다.\n",
    "\n",
    "* Width: 각 레이어의 width를 키우면 정확도가 높아지지만 계산량이 제곱에 비례하여 증가한다.\n",
    "\n",
    "* Resolution: 입력 이미지의 해상도를 키우면 더 세부적인 feature를 학습할 수 있어 정확도가 높아지지만 마찬가지로 계산량이 제곱에 비례해 증가한다.\n",
    "\n",
    "<img src=\"https://greeksharifa.github.io/public/img/2022-03-01-EfficientNet/fig03.png\" width=\"500\" height=\"300\"/>  \n",
    "\n",
    "-----\n",
    "\n",
    "#### Compound Model Scaling \n",
    "\n",
    "직관적으로, 더 높은 해상도의 이미지에 대해서는, 네트워크를 깊게 만들어서 더 넓은 영역에 걸쳐 있는 feature(by larger receptive fields)를 더 잘 잡아낼 수 있도록 하는 것이 유리하다.  \n",
    "\n",
    "또, 더 큰 이미지일수록 세부적인 내용도 많이 담고 있어서, 이를 잘 잡아내기 위해서는 layer의 width를 증가시킬 필요가 있다.  \n",
    "\n",
    "즉, 이 depth, width, resolution이라는 세 가지 변수는 밀접하게 연관되어 있으며, 이를 같이 움직이는 것이 도움이 될 것이라고 생각할 수 있다.\n",
    "\n",
    "계산량은 깊이에 비례하고, 나머지 두 변수에 대해서 그 제곱에 비례하므로 다음과 같은 비율로 변수들이 움직이게 정할 수 있다.\n",
    "\n",
    "<img src=\"https://greeksharifa.github.io/public/img/2022-03-01-EfficientNet/eq03.png\" width=\"500\" height=\"300\"/>  \n",
    "\n",
    "\n",
    "$ \\alpha \\cdot \\beta^2 \\cdot \\gamma^2 \\approx 2 $ 로 맞춰서 전체 계산량을 $2^\\phi $비례하게 잡았다.\n",
    "\n",
    "\n",
    "----\n",
    "\n",
    "\n",
    "#### EfficientNet Architecture \n",
    "\n",
    "<img src=\"https://greeksharifa.github.io/public/img/2022-03-01-EfficientNet/tab01.png\" width=\"500\" height=\"300\"/>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
