{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b294e921",
   "metadata": {},
   "source": [
    "## 경사 하강법(Gradient Descent)란 무엇인가요?\n",
    "\n",
    "손실함수 값이 낮아지는 방향으로 독립 변수 값을 변형시켜가면서 최종적으로는 최소 함수 값을 갖도록 하는 독립 변수 값을 찾는 방법이다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2ed83e",
   "metadata": {},
   "source": [
    "## 경사 하강법에서 학습률의(Learning rate) 값은 어떤 역할을 하나요?\n",
    "\n",
    "경사하강법에서 다음 지점으로 얼마나 갈 것인가를 결정하는 파라미터 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7b5542",
   "metadata": {},
   "source": [
    "## 경사 하강법이 가지는 문제점은 무엇인가요?\n",
    "\n",
    "* 학습 데이터가 많은 대규모 문제에서는 모든 데이터를 적용하여 가중치를 구해야 하는데 이는 많은 컴퓨팅 자원 소모량을 요구한다.  \n",
    "\n",
    "* 가중치 초기 설정값에 따라 극솟값 함정에 빠지는 경우가 존재한다. 경사하강법의 목적은 비용함수의 최솟값을 구하는 것이다. 최솟값과 극솟값 모두 미분계수의 값이 0이기 때문에 충분히 극솟값에 수렴할 수 있다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b771a440",
   "metadata": {},
   "source": [
    "## 확률적 경사 하강법(Stochastic Gradient Descent)란 무엇인가요?\n",
    "\n",
    "확률적 경사 하강법(Stochastic Gradient Descent)은 추출된 데이터 한개에 대해서 그래디언트를 계산하고, 경사 하강 알고리즘을 적용하는 방법을 말한다. 전체 데이터를 사용하는 것이 아니라, 랜덤하게 추출한 일부 데이터를 사용하는 것이다. 따라서 학습 중간 과정에서 결과의 진폭이 크고 불안정하며, 속도가 매우 빠르다. 또한, 데이터 하나씩 처리하기 때문에 오차율이 크고 GPU의 성능을 모두 활용하지 못하는 단점을 가진다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f2202a",
   "metadata": {},
   "source": [
    "## 확률적 경사 하강법과 배치 경사 하강법의 차이점은 무엇인가요?\n",
    "\n",
    "확률적 경사하강법은  매 스템에서 한개의 샘플을 무작위로 선택하고 그 하나의 샘플에 대한 그레디언트를 계산한다. 반면에 배치 경사 하강법은 매 스템에서 전체 훈련 세트를 사용해 그레디언트를 계산한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5555c7f",
   "metadata": {},
   "source": [
    "## 학습 곡선은 무엇인가요?\n",
    "\n",
    "훈련 데이터에 대한 모델의 성능과 검증 데이터에 대한 모델의 성능이 훈련 데이터의 양에 따라 어떻게 변화해가는지를 표시한 그래프이다. \n",
    "\n",
    "편향과 분산이란 무엇이고 모델의 복잡도와 어떤 관계가 있나요?학습곡선을 통해 모델이 underfit 되고 있는지, overfit 되고 있는지, 또는 그 외의 문제가 있는지를 알 수 있습니다. 이런 문제점을 체크함으로써 모델의 성능을 높이기 위해 데이터를 추가해야 하는지, feature를 늘려야 하는지, 모델의 크기를 늘려야 하는지 다른 문제를 봐야하는지를 알 수 있게 된다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddd8558",
   "metadata": {},
   "source": [
    "## 편향과 분산이란 무엇이고 모델의 복잡도와 어떤 관계가 있나요?\n",
    "\n",
    "* 편향 :예측이 정답에서 얼마나 떨어져 있는지를 반영\n",
    "* 분산 : 예측의 변동폭이 얼마나 큰지를 반영\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* 편향: 일반화 오차중에서 편향은 잘못된 가정으로 인한 것이다. 데이터가 실제로는 2차인데 선형으로 가정하는 경우, 편향이 큰 모델은 훈련데이터에 과소적합되기 쉽다.\n",
    "* 분산: 훈련데이터에 있는 작은 변동에 모델이 과도하게 민감하기 때문에 나타난다. 자유도가 높은 모델(예를 들면 고차다항회귀모델)이 높은 분산을 가지기 쉬워 훈련 데이터에 과대적합되는 경향이 있다.\n",
    "* 줄일 수 없는 오차: 데이터 자체에 있는 잡음 때문에 발생한다. 이 오차를 줄일 수 있는 유일한 방법은 데이터에서 잡음을 제거하는 것이다.\n",
    "    모델의 복잡도가 커지면 통상적으로 분산이 늘어나고 편향은 줄어든다. 반대로 모델의 복잡도가 줄어들면 편향이 커지고 분산이 작아진다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a151e874",
   "metadata": {},
   "source": [
    "## 규제란 무엇인가요?\n",
    "\n",
    "과대적합을 완화하기 위한 일반적인 방법으로 모델 복잡도에 제한을 두어 가중치가 작은 값을 가지도록 강제하는 것이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4307286",
   "metadata": {},
   "source": [
    "## 어떤 경우에서 릿지, 라쏘, 엘라스틱넷을 사용하나요?\n",
    "\n",
    "적어도 규제가 약간 있는 것이 대부분의 경우에 좋으므로 일반적으로 평범한 선형회귀는 피해야한다.릿지가 기본이 되지만 쓰이는 특성이 몇 개뿐이라고 의심되면 라쏘나 엘라스틱넷이 좋다. 이 모델들은 불필요한 특성의 가중치를 0으로 만들어 줄것이다.\n",
    "특성 수가 훈련샘플 수보다 많거나 특성 몇개가 강하게 연관되어 있을 때는 보통 라쏘가 문제를 일으키므로 엘라스틱을 선호한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c490a946",
   "metadata": {},
   "source": [
    "## 로지스틱 회귀란 무엇인가요?\n",
    "회귀를 사용하여 데이터가 어떤 범주에 속할 확률을 0에서 1 사이의 값으로 예측하고 그 확률에 따라 가능성이 더 높은 범주에 속하는 것으로 분류해주는 지도 학습 알고리즘\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
