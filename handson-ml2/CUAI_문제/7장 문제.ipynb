{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9349781d",
   "metadata": {},
   "source": [
    "## 앙상블 학습이란 무엇인가요?\n",
    "\n",
    "여러 개의 분류기를 생성하고, 그 예측을 결합 함으로써 보다 정확한 예측을 도출하는 기법\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666b07ab",
   "metadata": {},
   "source": [
    "## 각 분류기가 약한 학습기일지라도 다수결 투표 분류기가 개별 분류기 보다 정확도가 높을 경우가 많은 이유는 무엇인가요?\n",
    "\n",
    "각 분류기가 약한 학습기일지라도 충분하게 많고 다양하다면 앙상블은 강한 학습기가 될 수 있따.큰 수의 법칙(law of large numbers) 때문이다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff9253a",
   "metadata": {},
   "source": [
    "## 앙상블 방법은 어떤 경우에서 최고의 성능을 발휘하나요?\n",
    "\n",
    "앙상블 방법은 예측기가 가능한 서로 독립적일 때 최고의 성능을 발휘한다. 다양한 분류기를 얻는 한 가지 방법은 각기 다른 알고리즘으로 학습시키는 것이다. 이렇게 하면 매우 다른 종류의 오차를 만들 가능성이 높기 때문에 앙상블 모델의 정확도를 향상시킨다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e95093",
   "metadata": {},
   "source": [
    "## 배깅과 페이스팅은 무엇인가요?\n",
    "\n",
    "다양한 분류기를 만드는 한 가지 방법은. 알고리즘을 사용하여 훈련세트의 서브셋을 무작위로 구성하여 분류기를 각기 다르게 학습시키는 것이다. 배깅과 페이스팅에서는 같은 훈련 샘플을 여러개의 예측기에 걸쳐 사용할 수 있다.하지만 배깅만이 한 예측기를 위해 같은 훈련 샘플을 여러 번 샘플링 할 수 있다.\n",
    "\n",
    "* 훈련세트에서 중복을 허용하여 샘플링하는 방식을 배깅(bootstrap aggregating)\n",
    "* 훈련세트에서 중복을 허용하지 않고 샘플링하는 방식을 페이스팅"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4f175d",
   "metadata": {},
   "source": [
    "## oob평가란 무엇인가요?\n",
    "\n",
    "배깅을 사용하면 어떤 샘플은 한 예측기를 위해 여러 번 샘플링 되고 어떤 것은 전혀 선택되지 않을 수 있다. 선택되지 않은 훈련 샘플의 나머지를 oob 샘플이라고 한다. 예측기가 훈련하는 동안에는 oob샘플을 사용하지 않으므로 별도의 검증 세트를 사용하지 않고 oob샘플을 사용해 평가 할 수 있다. 앙상블의 평가는 각 예측기의 oob평가를 평균하여 얻는다. 이를 oob평가라고 한다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813ae77a",
   "metadata": {},
   "source": [
    "## 랜덤 포레스트란 무엇이고 어떻게 구현할 수 있나요?\n",
    "\n",
    "랜덤 포레스트는 일반적으로 배깅 또는 페이스팅을 적용한 결정트리 앙상블 방법이다. \n",
    "\n",
    "전형적으로 max_samples를 훈련세트의 크기로 지정한다. BaggingClassifier에 DecisionTreeClassifier를 넣어 만드는 대신 결정 트리에 최적화되어 사용하기 편리한 RandomForestClassifier를 사용할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882e436e",
   "metadata": {},
   "source": [
    "## 랜덤 포레스트에서는 어떤 방식을 통해 트리를 만드나요?\n",
    "\n",
    "랜덤 포레스트는 몇가지 예외가 있지만 결정트리의 매개변수와 앙상블 자체를 제어하는데 필요한 BaggingClassifier의 매개변수를 모두 갖고 있다.\n",
    "\n",
    "랜덤 포레스트 알고리즘은 트리의 노드를 분할할 때 전체 특성 중에서 최선의 특성을 찾는 대신 무작위로 선택한 특성 후보 중에서 최적의 특성을 찾는 식으로 무작위성을 더 주입한다. 결국 트리를 더욱 다양하게 만들고 편향을 손해보는 대신 분산을 낮추어 전체적으로 더 훌륭한 모델을 만들어 준다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649a1f7f",
   "metadata": {},
   "source": [
    "## 부스팅이란 무엇인가요?\n",
    "부스팅은 약한 학습기를 여러 개 연결하여 강한 학습기를 만드는 앙상블 방법을 말한다. 부스팅 방법의 아이디어는 앞의 모델을 보완해 나가면서 일련의 예측기를 학습시키는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55478677",
   "metadata": {},
   "source": [
    "## AdaBoost와 Gradient boosting는 어떤 방식으로 작동하나요?\n",
    "\n",
    "이전 예측기를 보완하는 새로운 예측기를 만드는 방법은 이전 모델이 과소적합했던 훈련 샘플의 가중치를 더 높이는 것이다. 이렇게 하면 새로운 예측기는 학습하기 어려운 샘플에 점점 더 맞춰지게된다. 이것이 에이다부스트에서 사용하는 방식이다. \n",
    "\n",
    "에이다부스트 분류기를 만들 때 알고리즘이 기반이 되는 첫 번째 분류기를 훈련 세트에서 훈련 시키고 예측을 만든다. 그 다음 알고리즘이 잘못 분류된 훈련 샘플의 가중치를 상대적으로 높인다. 두번 째 분류기는 업데이트된 가중치를 사용해 훈련 세트에서 훈현하고 다시 예측을 만든다. 그 다음 다시 가중치를 업데이트하는 식으로 계속 진행 된다.\n",
    "\n",
    "모든 예측기가 훈련을 마치면 앙상블은 배깅이나 페이스팅과 비슷한 방식으로 예측을 만든다. 하지만 가중치가 적용된 훈련 세트의 전반적인 정확도에 따라 예측기 마다 다른 가중치가 적용된다.\n",
    "\n",
    "연속된 학습 기법에는 중용한 단점이 있다. 각 예측기는 이전 예측기가 훈련되고 평가된 후에 학습될 수 있기 때문에 병렬화 또는 분할을 할 수 없다. 결국 배깅이나 페이스팅만큼 확장성이 높지 않다.\n",
    "\n",
    "\n",
    "그레이디언트 부스팅은 앙상블에 이전까지의 오차를 보정하도록 예측기를 순차적으로 추가한다. 하지만 에이다부스트처럼 반복마다 샘플의 가중치를 수정하는 대신 이전 예측기가 만든 잔여오차에 새로운 예측기를 학습한다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79df4b42",
   "metadata": {},
   "source": [
    "## 스태킹이란 무엇인가요?\n",
    "\n",
    "여러 모델들을 활용해 각각의 예측 결과를 도출한 뒤 그 예측 결과를 결합해 최종 예측 결과를 만들어내는 것  \n",
    "\n",
    "따라서 스태킹 알고리즘에는 총 2가지 단계가 있는데 \n",
    "\n",
    "1. n 개의 모델로 학습 데이터로 학습 모델 생성\n",
    "2. n 개의 모델에서 학습을 마친 뒤 예측한 값들을 합쳐서 최종 예측"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
